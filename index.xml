<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Adapting Visual Foundation Models on Mario Koddenbrock</title><link>https://koddenbrock.com/</link><description>Recent content in Adapting Visual Foundation Models on Mario Koddenbrock</description><generator>Hugo -- 0.154.5</generator><language>en-us</language><lastBuildDate>Mon, 12 Jan 2026 00:00:00 +0000</lastBuildDate><atom:link href="https://koddenbrock.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Publications</title><link>https://koddenbrock.com/publications/</link><pubDate>Mon, 12 Jan 2026 00:00:00 +0000</pubDate><guid>https://koddenbrock.com/publications/</guid><description>&lt;h3 id="synthetic-data-enables-human-grade-microtubule-analysis-with-foundation-models-for-segmentation"&gt;&lt;a href="https://www.biorxiv.org/content/10.64898/2026.01.09.698597v2"&gt;Synthetic data enables human-grade microtubule analysis with foundation models for segmentation&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Koddenbrock, M., Westerhoff, J., Fachet, D., Reber, S., Gers, F., Rodner, E. &lt;em&gt;Under Review at PLOS Computational Biology.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This paper introduces SynthMT, a synthetic dataset for microtubule (MT) segmentation, to address the lack of large-scale labeled data. By evaluating various automated methods, we show that the SAM3 model, when fine-tuned on a small number of synthetic images, achieves near-perfect, and sometimes super-human, performance on real-world data. This demonstrates that synthetic data can enable fully automated and highly accurate MT segmentation. &lt;a href="https://DATEXIS.github.io/SynthMT-project-page"&gt;Interactive Project Page&lt;/a&gt;.&lt;/p&gt;</description></item><item><title/><link>https://koddenbrock.com/kudos/</link><pubDate>Sat, 20 Sep 2025 00:00:00 +0000</pubDate><guid>https://koddenbrock.com/kudos/</guid><description>&lt;h2 id="awards"&gt;Awards&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id="best-paper-award-ki-2025"&gt;&lt;a href="https://ki2025.gi.de/"&gt;Best Paper Award KI 2025&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;KI 2025&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For our paper: &lt;a href="https://link.springer.com/chapter/10.1007/978-3-032-02813-6_5"&gt;On the Domain Robustness of Contrastive Vision-Language Models&lt;/a&gt;
Koddenbrock, M., Hoffmann, R., Brodmann,D. &amp;amp; Rodner, E. (2025). &lt;em&gt;KI 2025.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id="gfai---young-researcher-award-2023"&gt;&lt;a href="https://www.gfai.de/aktuelles/presse/news/artikel/gfai-kuehrt-nachwuchsforscher-2023"&gt;GFaI - Young Researcher Award 2023&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;GFaI, 2023&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For my work on AI-based condition monitoring of a mechanically pulsating cardiac support system. This method combines statistics, signal processing, and artificial intelligence to enable precise and early detection of potential problems in the blood pump, thereby improving patient care. The technology particularly helps children and adolescents with heart failure, allowing them more mobility and freedom.&lt;/p&gt;</description></item></channel></rss>