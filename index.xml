<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Adapting Visual Foundation Models on Mario Koddenbrock</title><link>https://koddenbrock.com/</link><description>Recent content in Adapting Visual Foundation Models on Mario Koddenbrock</description><generator>Hugo -- 0.150.0</generator><language>en-us</language><lastBuildDate>Sat, 20 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://koddenbrock.com/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://koddenbrock.com/kudos/</link><pubDate>Sat, 20 Sep 2025 00:00:00 +0000</pubDate><guid>https://koddenbrock.com/kudos/</guid><description>&lt;h2 id="awards"&gt;Awards&lt;/h2&gt;
&lt;hr&gt;
&lt;h3 id="best-paper-award-ki-2025"&gt;&lt;a href="https://ki2025.gi.de/"&gt;Best Paper Award KI 2025&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;KI 2025&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For our paper: &lt;a href="https://link.springer.com/chapter/10.1007/978-3-032-02813-6_5"&gt;On the Domain Robustness of Contrastive Vision-Language Models&lt;/a&gt;
Koddenbrock, M., Hoffmann, R., Brodmann,D. &amp;amp; Rodner, E. (2025). &lt;em&gt;KI 2025.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id="gfai---young-researcher-award-2023"&gt;&lt;a href="https://www.gfai.de/aktuelles/presse/news/artikel/gfai-kuehrt-nachwuchsforscher-2023"&gt;GFaI - Young Researcher Award 2023&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;GFaI, 2023&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For my work on AI-based condition monitoring of a mechanically pulsating cardiac support system. This method combines statistics, signal processing, and artificial intelligence to enable precise and early detection of potential problems in the blood pump, thereby improving patient care. The technology particularly helps children and adolescents with heart failure, allowing them more mobility and freedom.&lt;/p&gt;</description></item><item><title>Publications</title><link>https://koddenbrock.com/publications/</link><pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate><guid>https://koddenbrock.com/publications/</guid><description>&lt;h3 id="on-the-domain-robustness-of-contrastive-vision-language-models"&gt;&lt;a href="https://link.springer.com/chapter/10.1007/978-3-032-02813-6_5"&gt;On the Domain Robustness of Contrastive Vision-Language Models&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Koddenbrock, M., Hoffmann, R., Brodmann, D. &amp;amp; Rodner, E. (2025). &lt;em&gt;KI 2025.&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We present DeepBench, a framework for assessing the domain-specific robustness of vision-language models (VLMs). Unlike standard benchmarks, DeepBench uses an LLM to generate realistic, context-aware image corruptions tailored to target domains, without requiring labels. Evaluating multiple contrastive VLM architectures across six real-world domains, we find substantial variability in robustness, underscoring the need for domain-aware evaluation. &lt;a href="https://github.com/ml-lab-htw/deepbench"&gt;DeepBench is open-source&lt;/a&gt;.&lt;/p&gt;</description></item></channel></rss>